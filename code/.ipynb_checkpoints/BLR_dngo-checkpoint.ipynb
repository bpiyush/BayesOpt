{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_linear_regression import load_data, Task_BLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "from pybnn import DNGO\n",
    "from pybnn.util.normalization import zero_mean_unit_var_normalization, zero_mean_unit_var_denormalization\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', size=15.0, family='serif')\n",
    "plt.rcParams['figure.figsize'] = (12.0, 8.0)\n",
    "plt.rcParams['text.latex.preamble'] = [r\"\\usepackage{amsmath}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyp(arr):\n",
    "    hyperparams = {}\n",
    "    hyperparams['K'] = {'value': int(arr[0]), 'description': 'Kernel Dimension', 'type': 'discrete', 'range':[-4, 4]}\n",
    "    hyperparams['beta'] = {'value': float(arr[1]), 'description': 'BLR Hyperparameter', 'type': 'continuous', 'range':[-4, 4]}\n",
    "    hyperparams['lambda'] = {'value': float(arr[2]), 'description': 'BLR Hyperparameter', 'type': 'continuous', 'range':[-1, 1]}\n",
    "    hyperparams['metainfo'] = ['K', 'beta', 'lambda']\n",
    "    return hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_cval, y_cval), (X_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeta_train = [[2, 1.0, 1.0], [4, 1.0, 1.0], [2, 4.0, 1.0], [3, 4.0, 1.0], \n",
    "              [4, 4.0, 1.0], [5, 4.0, 1.0], [4, 2.0, 3.0], [5, 10.0, 2.0]]\n",
    "eta_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n"
     ]
    }
   ],
   "source": [
    "for x in zeta_train:\n",
    "    task = Task_BLR(hyperparams=get_hyp(x))\n",
    "    eta_train.append(task.metric(X_cval, y_cval, X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeta_train = np.array(zeta_train)\n",
    "zeta_train = zeta_train.reshape((len(zeta_train), 3))\n",
    "eta_train = np.array(eta_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zeta_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 9.239736\n",
      "         Iterations: 50\n",
      "         Function evaluations: 131\n"
     ]
    }
   ],
   "source": [
    "model = DNGO(do_mcmc=False)\n",
    "model.train(zeta_train, eta_train, do_optimize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_val = np.random.randint(1, 10, 25)\n",
    "b_val = np.linspace(0.5, 10, 25)\n",
    "c_val = np.linspace(0.5, 2.5, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeta_cval = np.array([[a_val[i], b_val[i], c_val[i]] for i in range(len(a_val)) ])\n",
    "zeta_cval = zeta_cval.reshape((len(a_val), 3))\n",
    "eta_cval = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n"
     ]
    }
   ],
   "source": [
    "for x in zeta_cval:\n",
    "    task = Task_BLR(hyperparams=get_hyp(x))\n",
    "    eta_cval.append(task.metric(X_cval, y_cval, X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, v = model.predict(zeta_cval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.82012269, 1.93943012, 1.8573208 , 1.95607164, 2.06337008,\n",
       "        2.07092689, 2.12699167, 2.15427483, 3.2593986 , 2.24784511,\n",
       "        4.06673967, 2.25936145, 2.40806817, 2.28885957, 2.45409496,\n",
       "        2.31949932, 3.82338568, 2.41108929, 2.51642849, 4.33850737,\n",
       "        3.54977111, 3.48876091, 2.46873297, 2.56600914, 3.3411218 ]),\n",
       " array([0.05181935, 0.06235678, 0.08813728, 0.06906947, 0.04638972,\n",
       "        0.04708569, 0.01325157, 0.05298676, 0.05012453, 0.00937065,\n",
       "        0.02687865, 0.06652197, 0.0172608 , 0.09867063, 0.02575335,\n",
       "        0.11363078, 0.21605983, 0.05365176, 0.03433472, 0.17533717,\n",
       "        0.37143848, 0.38602072, 0.05780251, 0.03403178, 0.39036131]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 25)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(m), len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_opt1 = get_hyp(list(zeta_cval[np.argmax(eta_cval)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters to be optimized:  K ,beta ,lambda\n"
     ]
    }
   ],
   "source": [
    "task_1 = Task_BLR(hyperparams=hyp_opt1)\n",
    "metric_value = task_1.metric(X_cval, y_cval, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.3380520764172"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesOptimize(object):\n",
    "    \"\"\"docstring for BayesOptimize\"\"\"\n",
    "    def __init__(self, D_task, D_surrogate):\n",
    "        super(BayesOptimize, self).__init__()\n",
    "        \n",
    "        (self.X_train, self.y_train), (self.X_cval, self.y_cval), (self.X_test, self.y_test) = D_task\n",
    "        self.D_surrogate = D_surrogate\n",
    "        self.zeta_train, self.eta_train = self.D_surrogate\n",
    "    \n",
    "    def posterior_prediction(self, zeta_test):\n",
    "        mean, var = self.dngo_model.predict(zeta_test)\n",
    "        return mean, var\n",
    "    \n",
    "    def expected_improvement(self, zeta_test):\n",
    "        zeta_train, eta_train = self.D_surrogate\n",
    "        eta_curr_best = np.max(eta_train)\n",
    "        \n",
    "        mean, var = self.posterior_prediction(zeta_test)\n",
    "        gamma = (eta_curr_best - mean)/var\n",
    "        \n",
    "        std_gaussian = ss.norm(0.0, 1.0)\n",
    "        \n",
    "        a = [std_gaussian.cdf(x) for x in gamma]\n",
    "        b = [std_gaussian.pdf(x) for x in gamma]\n",
    "        \n",
    "        return np.multiply(var, np.multiply(gamma, a) + b)\n",
    "    \n",
    "    def find_zeta_new(self, zeta_test):\n",
    "        ei = self.expected_improvement(zeta_test)\n",
    "        idx = np.argmax(ei)\n",
    "        \n",
    "        return zeta_test[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_prediction(zeta_test, dngo_model):\n",
    "    mean, var = dngo_model.predict(zeta_test)\n",
    "    return mean, var\n",
    "\n",
    "def expected_improvement(zeta_test, dngo_model, D_surrogate):\n",
    "    zeta_train, eta_train = D_surrogate\n",
    "    eta_curr_best = np.max(eta_train)\n",
    "\n",
    "    mean, var = posterior_prediction(zeta_test, dngo_model)\n",
    "    gamma = (eta_curr_best - mean)/var\n",
    "\n",
    "    std_gaussian = ss.norm(0.0, 1.0)\n",
    "\n",
    "    a = [std_gaussian.cdf(x) for x in gamma]\n",
    "    b = [std_gaussian.pdf(x) for x in gamma]\n",
    "\n",
    "    return np.multiply(var, np.multiply(gamma, a) + b)\n",
    "\n",
    "def find_zeta_new(zeta_test, dngo_model, D_surrogate):\n",
    "    ei = expected_improvement(zeta_test, dngo_model, D_surrogate)\n",
    "    idx = np.argmax(ei)\n",
    "\n",
    "    return zeta_test[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dngo_model = DNGO(do_mcmc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_val = np.random.randint(1, 10, 25)\n",
    "b_val = np.linspace(0.5, 10, 25)\n",
    "c_val = np.linspace(0.5, 2.5, 25)\n",
    "\n",
    "zeta_test = np.array([[a_val[i], b_val[i], c_val[i]] for i in range(len(a_val)) ])\n",
    "zeta_test = zeta_test.reshape((len(a_val), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_cval, y_cval), (X_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n"
     ]
    }
   ],
   "source": [
    "zeta_train = [[2, 1.0, 1.0], [4, 1.0, 1.0], [2, 4.0, 1.0], [3, 4.0, 1.0], \n",
    "              [4, 4.0, 1.0], [5, 4.0, 1.0], [4, 2.0, 3.0], [5, 10.0, 2.0]]\n",
    "eta_train = []\n",
    "\n",
    "for x in zeta_train:\n",
    "    task = Task_BLR(hyperparams=get_hyp(x))\n",
    "    eta_train.append(task.metric(X_cval, y_cval, X_train, y_train))\n",
    "\n",
    "zeta_train = np.array(zeta_train)\n",
    "zeta_train = zeta_train.reshape((len(zeta_train), 3))\n",
    "eta_train = np.array(eta_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -8.863165\n",
      "         Iterations: 51\n",
      "         Function evaluations: 130\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -15.256803\n",
      "         Iterations: 68\n",
      "         Function evaluations: 162\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -12.992252\n",
      "         Iterations: 52\n",
      "         Function evaluations: 130\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -18.423181\n",
      "         Iterations: 60\n",
      "         Function evaluations: 151\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -19.678806\n",
      "         Iterations: 49\n",
      "         Function evaluations: 129\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -19.322399\n",
      "         Iterations: 58\n",
      "         Function evaluations: 133\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -26.841329\n",
      "         Iterations: 53\n",
      "         Function evaluations: 137\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -24.426633\n",
      "         Iterations: 56\n",
      "         Function evaluations: 134\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -24.726528\n",
      "         Iterations: 64\n",
      "         Function evaluations: 148\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -28.935336\n",
      "         Iterations: 48\n",
      "         Function evaluations: 121\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -30.051348\n",
      "         Iterations: 50\n",
      "         Function evaluations: 122\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -42.701635\n",
      "         Iterations: 56\n",
      "         Function evaluations: 137\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -40.063142\n",
      "         Iterations: 52\n",
      "         Function evaluations: 125\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -36.779421\n",
      "         Iterations: 66\n",
      "         Function evaluations: 155\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -34.691842\n",
      "         Iterations: 49\n",
      "         Function evaluations: 122\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -45.243875\n",
      "         Iterations: 48\n",
      "         Function evaluations: 133\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -44.335503\n",
      "         Iterations: 46\n",
      "         Function evaluations: 116\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -45.914961\n",
      "         Iterations: 53\n",
      "         Function evaluations: 122\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -51.852886\n",
      "         Iterations: 55\n",
      "         Function evaluations: 137\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -58.289488\n",
      "         Iterations: 52\n",
      "         Function evaluations: 133\n",
      "Hyperparameters to be optimized:  K ,beta ,lambda\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_epochs):\n",
    "    D_task = (X_train, y_train), (X_cval, y_cval), (X_test, y_test)\n",
    "    D_surrogate = zeta_train, eta_train  \n",
    "    \n",
    "    dngo_model.train(zeta_train, eta_train, do_optimize=True)\n",
    "    \n",
    "    zeta_new = find_zeta_new(zeta_test, dngo_model, D_surrogate)\n",
    "    hyp_new = get_hyp(list(zeta_new))\n",
    "    task_1 = Task_BLR(hyperparams=hyp_new)\n",
    "    eta_new = task_1.metric(X_cval, y_cval, X_train, y_train)\n",
    "\n",
    "    zeta_train = np.concatenate((zeta_train, [zeta_new]), axis=0)\n",
    "    eta_train = np.concatenate((eta_train, [eta_new]), axis=0)\n",
    "\n",
    "    continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argmax(eta_train)\n",
    "optimal = zeta_train[idx]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 4., 1.])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eta_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_hyperparameters(self):\n",
    "    a_val = np.random.randint(1, 10, 25)\n",
    "    b_val = np.linspace(0.5, 10, 25)\n",
    "    c_val = np.linspace(0.5, 2.5, 25)\n",
    "\n",
    "    zeta_test = np.array([[a_val[i], b_val[i], c_val[i]] for i in range(len(a_val)) ])\n",
    "    zeta_test = zeta_test.reshape((len(a_val), 3))\n",
    "\n",
    "    for i in range(self.num_epochs):\n",
    "        zeta_new = self.find_zeta_new(zeta_test)\n",
    "        hyp_new = get_hyp(list(zeta_new))\n",
    "        task_1 = Task_BLR(hyperparams=hyp_new)\n",
    "        eta_new = self.get_eta_new(zeta_new)\n",
    "\n",
    "        self.zeta_train = np.concatenate((self.zeta_train, [zeta_new]), axis=0)\n",
    "        self.eta_train = np.concatenate((self.eta_train, [eta_new]), axis=0)\n",
    "\n",
    "        self.dngo_model.train(self.zeta_train, self.eta_train, do_optimize=True)\n",
    "        continue\n",
    "\n",
    "    idx = np.argmax(self.eta_train)\n",
    "    return self.zeta_train[idx]    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
